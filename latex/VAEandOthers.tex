\chapter*{Relationship of $\beta$-VAE to Other Fields}
$\beta$-VAEs use a weighted optimization function allowing for customizable trade-off between the reconstruction error and the KL term.\\
In this part of the paper, the authors present $\beta$-VAEs in the terminology of statistical mechanics in order to discuss the convergence of decoders.\\
They model the statistical mechanics problem in the following way:
\begin{description}
  \item[$\bullet$ order parameter $u(\beta)$] = $\E\left[\norm{x - g(z)}^2\right]$
  \item[$\bullet$ critical temperature points] $\beta_c$
  \item[$\bullet$ phase transitions] are detected by areas of high-curvature (see picture below)
\end{description}
In this part of the paper, the represent the latent space using an orthogonal basis $\phi$ and denote $\phi_a:\mathcal{R}^{d_z}\to\{0,1\}$.

\section*{Stationary Point for Langrangian of ELBO}
Before we can show, the relationship of $\beta$-VAEs we must develop the stationary points as we did for the ELBO function.
\begin{gather*}
L_{\lambda} = \E_{\rho(x)}\left[KL[q(z|x) \| \pi(z)] + \lambda^{T}\E_{q(z|x)}[\mathcal{C}(x, g(z))\right]
\end{gather*}
We will now find the partial derivatives of the GECO function by a decoder, $g(z)$, and an encoder, $q(z|x)$.\\
\subsection*{Decoder}
\begin{gather*}
\frac{\partial}{\partial g(z)}\E_{\rho(x)}\left[KL[q(z|x) \| \pi(z)] + \lambda^{T}\E_{q(z|x)}[\mathcal{C}(x, g(z))\right] = \lambda^{T}\E_{\rho(x)}[q(z|x)\frac{\partial \mathcal{C}(x, g(z))}{\partial g(z)}
\end{gather*}
Setting the partial derivative to zero and writing the expectation explicitly
\begin{gather*}
0 = \frac{\lambda^{T}}{n}\sum_{x}q(z|x)\frac{\partial \mathcal{C}(x, g(z))}{\partial g(z)}
\end{gather*}
The solution of which depends on the reconstruction constraint used.\par
\subsection*{Encoder}
\setcounter{equation}{0}
\begin{equation}
\frac{\partial}{\partial q(z|x)}\E_{\rho(x)}\left[KL[q(z|x) \| \pi(z)] + \lambda^{T}\E_{q(z|x)}[\mathcal{C}(x, g(z))\right]
\end{equation}
\begin{equation}
\frac{\partial}{\partial q(z|x)} \frac{1}{n}\sum_{x}\sum_{z} q(z|x)\ln{\frac{q(z|x)}{\pi(z)}} + q(z|x)\lambda^{T}\mathcal{C}(x, g(z))
\end{equation}
\begin{equation}
\frac{1}{n}[1 + \ln{\frac{q(z|x)}{\pi(z)}} + \lambda^{T}\mathcal{C}(x, g(z))]
\end{equation}
The paper only shows a proportional relationship, ignoring the constants. The simplified equation is:
\begin{equation}
\ln{\frac{q(z|x)}{\pi(z)}} + \lambda^{T}\mathcal{C}(x, g(z))
\end{equation}
After setting the partial derivative to zero, we derive:
\begin{gather*}
q(z|x) \propto \pi(z)e^{-\lambda^{T}\mathcal{C}(x, g(z)}
\end{gather*}

\section*{Equipartition of energy in $\beta$-VAEs}
Using the reconstruction error, $\mathcal{C}(x, g(z)$ as the Hamiltonian function $H(x,z)$, let us define the following. $\Omega(x,z_0)$ is the set of points in the latent space where the Hamiltonian is approximately constant. That is to say $\Omega(x,z_0) = \{z'||H(x,z')-H(x,z_0)|\leq\epsilon\}$. We define $\Omega_a$ as the set $\{\Omega(x,z_0),\forall x$ and $z_0\}$.\\
Using this definition if we hold $x$ constant, the function $H(x,z)$ only has $|z|=m$ possible distinct values, which we will enumerate as $H_ia$ relative to $\Omega_a$.
Additionally, we define the probability of a sample from the prior being in 
Above we saw above,
\begin{gather*}
q(z|x) \propto \pi(z)e^{-\lambda^{T}\mathcal{C}(x, g(z)}
\end{gather*}
Therefore, after dividing by the necessary constant
\begin{gather*}
q_i(z) = \pi(z)\sum_a\frac{e^{H_ia}{\beta}}{\sum_b e^{H_ib}{\beta}}\mathcal{I}_{z\in\Omega_a}
\end{gather*}




